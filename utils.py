import numpy as np
import itertools

class Dataset:
    def __init__(self,x,y,v2i,i2v):
        self.x,self.y = x,y
        self.v2i,self.i2v = v2i,i2v
        self.vocab = v2i.keys()

    def sample(self,n):
        b_idx = np.random.randint(0,len(self.x),n)
        bx,by = self.x[b_idx],self.y[b_idx]
        return bx,by

    @property
    def num_word(self):
        return len(self.v2i)

def process_w2v_data(corpus,skip_window=2,method='cbow'):
    # ------start process data---------
    all_words = [sentence.split(" ") for sentence in corpus]
    all_words = np.array(list(itertools.chain(*all_words)))
    vocab,v_count = np.unique(all_words,return_counts=True)
    print('vocal',vocab)
    print('v-count',v_count)
    # vocab1 = vocab[np.argsort(v_count)]
    # print(vocab1)
    vocab2 = vocab[np.argsort(v_count)[::-1]]    # 按照个数大小从大到小排列vocab
    v2i = {v:i for i,v in enumerate(vocab2)}
    i2v = {i:v for v,i in v2i.items()}

    pairs = []
    js = [i for i in range(-skip_window,skip_window+1) if i!=0]
    for c in corpus:
        words = c.split(' ')
        w_idx = [v2i[w] for w in words]
        if method == 'skip_gram':
            for i in range(len(w_idx)):
                for j in js:
                    if i+j<0 or i+j>=len(w_idx):
                        continue
                    pairs.append((w_idx[i],w_idx[i+j]))    #(center,context)
        elif method.lower()=='cbow':
            for i in range(skip_window,len(w_idx)-skip_window):
                context = []
                for j in js:
                    context.append(w_idx[i+j])
                pairs.append(context+[w_idx[i]])
        else:
            raise ValueError
    pairs = np.array(pairs)
    print('20 example pairs:\n',pairs[:20])
    if method=='skip_gram':
        x,y = pairs[:,0],pairs[:,1]
    elif method=='cbow':
        x,y = pairs[:,:-1],pairs[:,-1]
    else:
        raise ValueError
    print(x)
    print(y)
    return Dataset(x,y,v2i,i2v)



if __name__ == '__main__':
    corpus = [
        # number
        '5 2 4 8 6 2 3 6 4',
        '4 8 5 6 9 5 5 6',
        "1 1 5 2 3 3 8",
        "3 6 9 6 8 7 4 6 3",
        "8 9 9 6 1 4 3 4",
        "1 0 2 0 2 1 3 3 3 3 3",
        "9 3 3 0 1 4 7 8",
        "9 9 8 5 6 7 1 2 3 0 1 0",
        # alphabets, expecting that 9 is close to letters
        "a t g q e h 9 u f",
        "e q y u o i p s",
        "q o 9 p l k j o k k o p",
        "h g y i u t t a e q",
        "i k d q r e 9 e a d",
        "o p d g 9 s a f g a",
        "i u y g h k l a s w",
        "o l u y a o g f s",
        "o p i u y g d a s j d l",
        "u k i l o 9 l j s",
        "y g i s h k j l f r f",
        "i o h n 9 9 d 9 f a 9",
    ]
    process_w2v_data(corpus)



import tensorflow as tf
print(tf.__version__)